{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import faiss\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import process_md as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 document pages.\n"
     ]
    }
   ],
   "source": [
    "def load_pdf(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "# Provide the path to your PDF file\n",
    "# pdf_path = r\"D:\\Downloads\\Chapter 4.pdf\"  \n",
    "pdf_path=r\"pdfs/Chapter 4.pdf\"\n",
    "docs = load_pdf(pdf_path)\n",
    "print(f\"Loaded {len(docs)} document pages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 5 text chunks.\n"
     ]
    }
   ],
   "source": [
    "# def chunk_text(docs, chunk_size=500, chunk_overlap=100):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "#     chunks = text_splitter.split_documents(docs)\n",
    "#     return chunks\n",
    "\n",
    "file_path = \"data/journal.md\"  \n",
    "last_timestamp = \"2025-01-08 08:30:00\"  \n",
    "\n",
    "file=pm.read_markdown(file_path)\n",
    "\n",
    "text=pm.extract_new_content(file, last_known_timestamp=last_timestamp)\n",
    "\n",
    "chunks =pm.split_into_chunks(text, chunk_size=500, overlap=100)\n",
    "\n",
    "print(f\"Split into {len(chunks)} text chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pniki\\AppData\\Local\\Temp\\ipykernel_15188\\2136429511.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"llama3.2:latest\", base_url=\"http://localhost:11666\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store initialized with Llama3 embeddings.\n"
     ]
    }
   ],
   "source": [
    "def store_in_vector_db(chunks):\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3.2:latest\", base_url=\"http://localhost:11666\")  \n",
    "    db = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "db = store_in_vector_db(chunks)\n",
    "print(\"FAISS vector store initialized with Llama3 embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Response: The document appears to be a personal journal or diary written by someone who is a graduate student in academia, likely working on a PhD project involving artificial intelligence (AI) and machine learning. The entries are brief and humorous, detailing the author's struggles with their research, frustration with academic requirements, and feelings of uncertainty about their career path.\n",
      "\n",
      "The writer seems to be struggling with various aspects of their PhD journey, including:\n",
      "\n",
      "* Confusion about their research direction\n",
      "* Difficulty understanding complex concepts, such as SVM optimizations and deep learning interpretability\n",
      "* Frustration with debugging and data preprocessing issues\n",
      "* Feeling overwhelmed by the amount of work and pressure to produce results\n",
      "* Questioning whether they are making the right career choice\n",
      "\n",
      "Despite these challenges, the writer also expresses moments of inspiration, creativity, and humor, such as watching cat videos or attending a talk on explainable AI.\n"
     ]
    }
   ],
   "source": [
    "def query_rag(db, query):\n",
    "    docs = db.similarity_search(query, k=3)  # Retrieve top 3 relevant chunks\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    \n",
    "    prompt = f\"Answer the following question based on the context below:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    response = ollama.chat(model=\"llama3.2:latest\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    \n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "query = \"This is a document of my rants to myself. There are pecific timestamps with each message. From this information help me write a summary of each day for my personal journal. Make sure to preserve the emotional information and make sure the writing is in first person\"\n",
    "# query = \"What does the document say about the president of the united sttates?\"\n",
    "response = query_rag(db, query)\n",
    "\n",
    "print(\"RAG Response:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hack_NCSU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
